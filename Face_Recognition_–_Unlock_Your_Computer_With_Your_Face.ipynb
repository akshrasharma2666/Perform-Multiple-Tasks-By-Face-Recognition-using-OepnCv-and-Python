{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mz3nJLzoa3h0"
   },
   "source": [
    "## Face Recognition â€“ Unlock Your Computer With Your Face!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "90EqqcRZa3h9"
   },
   "source": [
    "\n",
    "### Step 1 - Create Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "collapsed": false,
    "id": "OplT1L5Ya3h_",
    "outputId": "996148b2-fd27-4f30-b730-ecd4afc8c4b9"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load HAAR face classifier\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load functions\n",
    "def face_extractor(img):\n",
    "    # Function detects faces and returns the cropped face\n",
    "    # If no face detected, it returns the input image\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    if faces is ():\n",
    "        return None\n",
    "    \n",
    "    # Crop all faces found\n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "\n",
    "    return cropped_face"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W9A6RhqAa3iF"
   },
   "source": [
    "### Step 2 - Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "id": "WT4KOlJUa3iH",
    "outputId": "5bd3bb8f-662d-4b99-8adf-5dac05fc1b46"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "# Get the training data we previously made\n",
    "class model_train:\n",
    "    def __init__(self,user):\n",
    "        self.user = user\n",
    "    def capture(self):\n",
    "        # Initialize Webcam\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        count = 0\n",
    "\n",
    "        # Collect 100 samples of your face from webcam input\n",
    "        while True:\n",
    "\n",
    "            ret, frame = cap.read()\n",
    "            if face_extractor(frame) is not None:\n",
    "                count += 1\n",
    "                face = cv2.resize(face_extractor(frame), (200, 200))\n",
    "                face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Save file in specified directory with unique name\n",
    "                file_name_path = './faces/{}/'.format(self.user) + str(count) + '.jpg'\n",
    "                cv2.imwrite(file_name_path, face)\n",
    "\n",
    "                # Put count on images and display live count\n",
    "                cv2.putText(face, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "                cv2.imshow('Face Cropper', face)\n",
    "\n",
    "            else:\n",
    "                print(\"Face not found\")\n",
    "                pass\n",
    "\n",
    "            if cv2.waitKey(1) == 13 or count == 100: #13 is the Enter Key\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()      \n",
    "        print(\"Collecting Samples Complete\")\n",
    "    def training(self):\n",
    "        data_path = './faces/{}/'.format(self.user)\n",
    "        onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]\n",
    "\n",
    "        # Create arrays for training data and labels\n",
    "        Training_Data, Labels = [], []\n",
    "\n",
    "        # Open training images in our datapath\n",
    "        # Create a numpy array for training data\n",
    "        for i, files in enumerate(onlyfiles):\n",
    "            image_path = data_path + onlyfiles[i]\n",
    "            images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            Training_Data.append(np.asarray(images, dtype=np.uint8))\n",
    "            Labels.append(i)\n",
    "\n",
    "        # Create a numpy array for both training data and labels\n",
    "        Labels = np.asarray(Labels, dtype=np.int32)\n",
    "\n",
    "        # Initialize facial recognizer\n",
    "        # model = cv2.face.createLBPHFaceRecognizer()\n",
    "        # NOTE: For OpenCV 3.0 use cv2.face.createLBPHFaceRecognizer()\n",
    "        # pip install opencv-contrib-python\n",
    "        # model = cv2.createLBPHFaceRecognizer()\n",
    "\n",
    "        face_user  = cv2.face_LBPHFaceRecognizer.create()\n",
    "        # Let's train our model \n",
    "        face_user.train(np.asarray(Training_Data), np.asarray(Labels))\n",
    "        print(\"Model trained sucessfully\")\n",
    "    def prediction(self,facial):\n",
    "        face_user.predict(facial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter first face name: Lalita\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Collecting Samples Complete\n",
      "Model trained sucessfully\n"
     ]
    }
   ],
   "source": [
    "face1 = input(\"Enter first face name: \")\n",
    "human1 = model_train(face1)\n",
    "human1.capture()\n",
    "human1.training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter second face name: Prabhjeet\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Collecting Samples Complete\n",
      "Model trained sucessfully\n"
     ]
    }
   ],
   "source": [
    "face2 = input(\"Enter second face name: \")\n",
    "human2 = model_train(face2)\n",
    "human2.capture()\n",
    "human2.training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zZpPp6b9a3iK"
   },
   "source": [
    "### Step 3 - Run Our Facial Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "id": "9twWsgVva3iK",
    "outputId": "4b4c6c4a-44af-4d06-e01c-f5c99536d9dd"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_detector(img, size=0.5):\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return img, []\n",
    "    \n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi, (200, 200))\n",
    "    return img, roi\n",
    "\n",
    "\n",
    "# Open Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    image, face = face_detector(frame)\n",
    "    \n",
    "    try:\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Pass face to prediction model\n",
    "        # \"results\" comprises of a tuple containing the label and the confidence value\n",
    "        results = human1.prediction(face)\n",
    "        # harry_model.predict(face)\n",
    "        \n",
    "        if results[1] < 500:\n",
    "            confidence = int( 100 * (1 - (results[1])/400) )\n",
    "            display_string = str(confidence) + '% Confident it is User'\n",
    "            \n",
    "        cv2.putText(image, display_string, (100, 120), cv2.FONT_HERSHEY_COMPLEX, 1, (255,120,150), 2)\n",
    "        \n",
    "        if confidence > 90:\n",
    "            cv2.putText(image, \"Hey Vimal\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "            os.system(\"msedge google.com\")\n",
    "            #os.system(\"wmplayer   c:\\lw.mp3\")\n",
    "            break\n",
    "         \n",
    "        else:\n",
    "            \n",
    "            cv2.putText(image, \"I dont know, how r u\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "\n",
    "    except:\n",
    "        cv2.putText(image, \"No Face Found\", (220, 120) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.putText(image, \"looking for face\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.imshow('Face Recognition', image )\n",
    "        pass\n",
    "        \n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "id": "051t50OWa3iN"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "prediction() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-219ce18ce80c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhuman1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhuman1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mface\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: prediction() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "results = human1.prediction(human1,face)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Face Recognition â€“ Unlock Your Computer With Your Face.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
